The O
goal O
is O
to O
identify O
entities O
from O
diﬀerent O
KGs B-Algothat O
refer O
to O
the O
same O
entity O
e O
g O
Mount O
Everest O
in O
DBpedia O
and O
Q513 O
in O
Wikidata O

Figure O
Framework O
of O
embedding O
based O
entity O
alignment O
techniques O
which O
embed O
the O
symbolic O
representations O
of O
a O
KG B-Algoas O
low O
dimensional O
vectors O
in O
a O
way O
such O
that O
the O
semantic O
relatedness O
of O
entities O
is O
captured O
by O
the O
geometrical O
structures O
of O
an O
embedding O
space O

It O
takes O
as O
input O
two O
diﬀerent O
KGs B-Algoand O
collects O
seed O
alignment O
between O
them O
using O
sources O

Existing O
KG B-Algoembedding O
models O
can O
be O
generally O
divided O
into O
three O
categories O
i O
translational O
models O
like O
TransE B-Algo
TransH B-Algo
TransR B-Algo
TransD B-Algo
semantic O
matching O
models O
e O
g O
DistMult B-Algo
ComplEx B-Algo
HolE B-Algo
SimplE B-Algo
RotatE B-Algo
and O
TuckER B-Algo
and O
iii O
deep O
models O
e O
g O
ProjE B-Algo
ConvE B-Algo
GCN B-Algo
KBGAN B-Algo
and O
DSKG B-Algo

A O
related O
area O
is O
network O
embedding O
which O
learns O
vertex O
representations O
to O
capture O
their O
proximity O

Recent O
studies O
also O
use O
statistical O
machine O
learning O
and O
crowdsourcing O
improve O
the O
accuracy O

Many O
existing O
approaches O
employ O
the O
translational O
models O
e O
g O
TransE B-Algo
to O
learn O
entity O
embeddings O
for O
alignment O
based O
on O
relation O
triples O

Also O
there O
are O
some O
approaches O
for O
heterogeneous O
information O
network O
alignment O
or O
cross O
lingual O
knowledge O
projection O
which O
may O
also O
be O
modiﬁed O
for O
entity O
alignment O

IPTransE B-Algo
models O
relation O
paths O
by O
inferring O
the O
equivalence O
between O
a O
direct O
relation O
and O
a O
multi O
hop O
path O

Semi O
supervised O
learning O
uses O
unlabeled O
data O
in O
training O
e O
g O
self O
training O
and O
co O
training O

Although O
OTEA B-Algo
and O
KECG B-Algo
claim O
that O
they O
are O
semi O
supervised O
approaches O
their O
learning O
strategies O
use O
MTransE B-Algo
IPTransE B-Algo
JAPE B-Algo
BootEA B-Algo
KDCoE B-Algo
NTAM B-Algo
GCNAlign B-Algo
AttrE B-Algo
IMUSE B-Algo
SEA B-Algo
RSN4EA B-Algo
GMNN B-Algo
MuGNN B-Algo
OTEA B-Algo
NAEA B-Algo
GCN B-Algo
MultiKE B-Algo
RDGCN B-Algo
KECG B-Algo
HGCN B-Algo
MMEA B-Algo
HMAN B-Algo
AKE B-Algo

Another O
work O
RSN4EA B-Algo
modiﬁes O
recurrent O
neural O
networks O
RNNs B-Algo
to O
model O
the O
sequence O
of O
entities O
and O
relations O
together O

JAPE B-Algo
exploits O
such O
correlations O
for O
entity O
alignment O
based O
on O
the O
assumption O
that O
similar O
entities O
should O
have O
similar O
correlated O
attributes O

AttrE B-Algo
proposes O
a O
character O
level O
encoder O
that O
is O
capable O
of O
dealing O
with O
unseen O
values O
in O
training O
phases O

Although O
IMUSE B-Algo
claims O
that O
it O
is O
an O
unsupervised O
approach O
it O
actually O
uses O
a O
preprocessing O
method O
to O
collect O
seed O
alignment O
with O
high O
string O
similarity O

It O
can O
be O
scaled O
to O
very O
large O
KGs B-Algoby O
using O
approximation O
algorithms O

For O
evaluation O
we O
design O
two O
baseline O
methods O
on O
the O
basis O
of O
existing O
graph O
sampling O
algorithms O

Random O
alignment O
sampling O
RAS B-Algo
randomly O
selects O
a O
ﬁxed O
size O
of O
entity O
alignment O
between O
two O
KGs B-Algoand O
then O
extracts O
the O
relation O
triples O
whose O
head O
and O
tail O
entities O
are O
both O
in O
the O
sampled O
entities O

In O
addition O
to O
the O
average O
degree O
and O
JS B-Algodivergence O
we O
further O
consider O
two O
metrics O
percentage O
of O
isolated O
entities O

Moreover O
we O
integrate O
several O
relation O
embedding O
models O
that O
have O
not O
been O
explored O
for O
entity O
alignment O
yet O
including O
three O
translational O
models O
TransH B-Algo
TransR B-Algo
and O
TransD B-Algo
three O
semantic O
matching O
models O
HolE B-Algo
SimplE B-Algo
and O
RotatE B-Algo
as O
well O
as O
two O
deep O
models O
ProjE B-Algo
and O
ConvE B-Algo

We O
also O
integrate O
two O
attribute O
embedding O
models O
AC2Vec B-Algo
and O
Label2Vec B-Algo
based O
on O
pre O
trained O
multilingual O
word O
embeddings O

TransH B-Algo
TransR B-Algo
TransD B-Algo
and O
HolE B-Algo
are O
developed O
by O
referring O
to O
the O
open O
source O
toolkit O

Notice O
that O
there O
are O
emerging O
approaches O
e O
g O
AliNet B-Algothat O
are O
contemporaneous O
to O
this O
paper O

The O
work O
in O
also O
shows O
that O
negative O
sampling O
can O
largely O
aﬀect O
the O
expressiveness O
of O
KG B-Algoembeddings O

To O
resolve O
the O
hubness O
and O
isolation O
problem O
we O
explore O
cross O
domain O
similarity O
as O
the O
alternative O
metric O

Most O
existing O
approaches O
use O
TransE B-Algo
or O
GCNs B-Algo
for O
KG B-Algoembedding O
due O
to O
their O
strong O
robustness O
and O
good O
generalizability O

To O
fill O
this O
gap O
we O
evaluate O
three O
translational O
models O
TransH B-Algo
TransR B-Algo
and O
TransD B-Algo
two O
deep O
models O
ProjE B-Algo
and O
ConvE B-Algo
as O
well O
as O
three O
semantic O
matching O
models O
HolE B-Algo
SimplE B-Algo
and O
RotatE B-Algo
for O
entity O
alignment O

We O
compare O
OpenEA B-Algo
with O
two O
famous O
open O
source O
conventional O
approaches O
for O
KG B-Algoalignment O
i O
e O
LogMap B-Algo
from O
the O
Semantic O
Web O
community O
and O
PARIS B-Algo
from O
the O
Database O
community O

Another O
possible O
solution O
is O
to O
use O
active O
learning O
or O
abductive O
learning O
to O
reduce O
the O
burden O
of O
data O
labeling O

We O
also O
notice O
that O
recent O
non O
Euclidean O
embeddings O
have O
demonstrated O
their O
eﬀectiveness O
in O
representing O
graph O
structured O
data O

A O
sampling O
technique O
namely O
SMOTE B-Algo
has O
been O
proposed O
that O
increases O
the O
number O
of O
minority O
class O
instances O
by O
creating O
artiﬁcial O
and O
non O
repeated O
samples O

The O
modiﬁed O
DTs B-Algo
for O
imbalanced O
classiﬁcation O
are O
HDDT B-Algo
CCPDT B-Algo
and O
iHDwDT B-Algo

Despite O
its O
simplicity O
kNN B-Algo
is O
considered O
as O
one O
of O
the O
top O
most O
inﬂuential O
data O
mining O
algorithms O

Dudani O
has O
proposed O
a O
distance O
based O
weighted O
kNN B-Algo
which O
provides O
more O
weights O
to O
closer O
neighbors O

Another O
variant O
of O
kNN B-Algo
approach O
Generalized O
Mean O
Distance O
based O
kNN B-Algo

GMDKNN B-Algo
has O
been O
presented O
by O
introducing O
multi O
generalized O
mean O
distance O
and O
the O
nested O
generalized O
mean O
distance O

In O
exemplar O
based O
kNN B-Algo
kENN B-Algo
we O
expand O
the O
decision O
boundary O
for O
the O
minority O
class O
by O
identifying O
the O
exemplar O
minority O
instances O

A O
weighting O
algorithm O
namely O
kNN B-Algo
and O
CCWKNN B-Algo
has O
been O
presented O
where O
the O
probability O
of O
feature O
values O
given O
the O
class O
labels O
is O
considered O
as O
weight O

Dubey O
and O
Pudi O
have O
proposed O
a O
weighted O
kNN B-Algo
WKNN B-Algo
which O
considers O
the O
class O
distribution O
in O
a O
wider O
region O
around O
a O
query O
instance O

To O
address O
this O
problem O
kNN B-Algo
has O
been O
extended O
using O
DST B-Algo
to O
better O
uncertain O
data O

Since O
Google O
ﬁrst O
released O
the O
knowledge O
graph O
the O
best O
summary O
for O
entities O
has O
been O
one O
of O
the O
main O
contributions O
in O
Google O
Search O

In O
addition O
entity O
summarization O
has O
been O
integrated O
into O
various O
applications O
such O
as O
document O
browsing O
Question O
Answering O
QA O
etc O

Most O
previous O
entity O
summarization O
methods O
are O
based O
on O
LDA B-Algomodels O
depending O
too O
much O
on O
the O
hand O
crafted O
templates O
for O
feature O
extraction O
as O
well O
as O
human O
expertise O
for O
feature O
selection O

To O
ﬁnd O
the O
most O
central O
triples O
RELIN B-Algo
and O
SUMMARUM B-Algo
compute O
the O
relatedness O
and O
informativeness O
based O
on O
the O
features O
extracted O
from O
hand O
crafted O
templates O

Meanwhile O
FACES B-Algo
and O
ESLDA B-Algo
introduce O
a O
clustering O
algorithm O
and O
LDA B-Algomodel I-Algo
for O
capturing O
multi O
aspect O
information O
respectively O

Recently O
deep O
learning O
methods O
relieve O
the O
dependency O
on O
human O
expertise O
in O
Natural O
Language O
Processing O
community O

To O
generate O
the O
summaries O
without O
human O
expertise O
an O
entity O
summarization O
method O
with O
a O
single O
layer O
attention O
ESA B-Algo
is O
proposed O
to O
calculate O
the O
attention O
score O
for O
each O
triple O

In O
ESLDA I-Algo
Pouriyeh O
et O
al O
stated O
the O
key O
point O
of O
learning O
word O
embeddings O
was O
the O
deﬁnition O
for O
words O

In O
Named O
Entity O
Recognition O
task O
the O
LSTM B-Algo
and O
BiLSTM B-Algo
has O
been O
widely O
used O
for O
automatic O
feature O
extraction O

For O
instance O
in O
order O
to O
automatically O
extract O
features O
from O
a O
small O
and O
supervised O
training O
corpus O
using O
LSTMCRF B-Algo
model I-Algo
was O
proposed O
by O
utilizing O
a O
BiLSTM B-Algo
for O
feature O
extraction O
and O
conditional B-Algo
random I-Algo
ﬁelds I-Algo
for O
entity O
recognition O

The O
BiLSTM B-Algo
extracted O
representative O
and O
contextual O
features O
of O
a O
word O
aligning O
with O
other O
words O
in O
the O
same O
sentence O

The O
single O
layer O
attention O
mechanism O
in O
ESA B-Algo
can O
not O
capture O
this O

One O
seminal O
work O
is O
NMT B-Algowhere O
the O
stacked O
layers O
are O
utilized O
to O
capture O
the O
information O
from O
a O
sentence O

Here O
instead O
of O
combining O
all O
attention O
layers O
to O
generate O
overall O
attention O
scores O

we O
directly O
output O
the O
attention O
scores O
from O
each O
attention O
layer O
for O
multi O
user O
preference O
simulation O
in O
user O
phase O
attention O

In O
NER O
a O
BiLSTM B-Algo
can O
maintain O
the O
independence O
and O
capture O
the O
intrinsic O
relationships O
among O
words O

Our O
baselines O
consist O
of O
some O
existing O
state O
of O
the O
art O
entity O
summarization O
methods O
including O
RELIN B-Algo
DIVERSUM B-Algo
CD B-Algo
FACES B-Algo
LinkSUM B-Algo
MPSUM B-Algo
and O
ESA B-Algo

Since O
ESA B-Algo
has O
been O
signiﬁcantly O
better O
than O
all O
other O
state O
of O
the O
art O
methods O
in O
our O
baselines O
we O
then O
compare O
the O
statistical O
signiﬁcance O
among O
ESA B-Algo
and O
AutoSUM B-Algo

For O
example O
MFLDA B-Algo
reduces O
the O
high O
dimension O
of O
heterogeneous O
data O
sources O
into O
lowrank O
matrices O
via O
matrix O
tri O
factorization O
which O
can O
help O
to O
explore O
and O
exploit O
their O
intrinsic O
and O
shared O
structure O

SIMCLDA B-Algo
translates O
the O
lncRNA O
disease O
association O
prediction O
problem O
into O
a O
recommendation O
which O
can O
be O
solved O
with O
inductive O
matrix O
completion O

For O
example O
RWRlncD B-Algo
infers O
potential O
human O
lncRNA O
disease O
associations O
by O
implementing O
the O
random O
walk O
with O
restart O
method O

IRWRLDA B-Algo
predicts O
novel O
disease O
associations O
by O
integrating O
known O
disease O
associations O
disease O
semantic O
similarity O
and O
various O
similarity O
measures O
and O
make O
prediction O

Another O
typical O
prediction O
algorithm O
is O
LRLSLDA B-Algo
which O
constructs O
a O
cost O
function O
in O
lncRNA O
and O
disease O
space O
and O
makes O
prediction O
by O
combining O
several O
classifiers O

LDAP B-Algo
predicts O
potential O
disease O
associations O
by O
using O
a O
bagging O
SVM B-Algo
classifier O
based O
on O
similarity O

LDAP B-Algo
fused O
different O
data O
source O
and O
make O
prediction O
based O
on O
bagging O
SVM B-Algo
classifier O

SIMCLDA B-Algo
predicted O
disease O
association O
based O
on O
inductive O
matrix O
completion O

KATZHMDA B-Algo
integrated O
known O
microbe O
disease O
associations O
and O
gaussian O
interaction O
profile O
for O
microbes O
and O
diseases O
and O
make O
prediction O
based O
on O
this O

Nuclear O
enriched O
abundant O
transcript O
NEAT1 B-Algo
was O
identified O
as O
the O
most O
significantly O
over O
expressed O
lncRNA O
in O
prostate O
cancer O
by O
using O
a O
combination O
of O
chromatin O
immunoprecipitation O

The O
architecture O
of O
neural O
networks O
has O
evolved O
a O
lot O
in O
recent O
years O
convolutional O
neural O
network O
CNN B-Algo
remains O
the O
most O
successful O
model O
in O
applications O
that O
can O
exploit O
grid O
like O
data O
structure O

Graph B-Algo
neural O
networks O
GNN B-Algo
aims O
at O
building O
deep O
learning O
methods O
for O
graph O
data O
such O
as O
social O
networks O
citation O
networks O
and O
the O
world O
wide O
web O
and O
its O
eﬀectiveness O
has O
been O
shown O
in O
many O
real O
world O
applications O

GCN B-Algo
is O
a O
prominent O
GNN B-Algo
variant O
which O
is O
an O
analogy O
of O
CNN B-Algo

Some O
recent O
researches O
focus O
on O
providing O
pooling O
methods O
that O
are O
applicable O
in O
GCNs B-Algo
such O
as O
DiffPool B-Algo
and O
SAGPool B-Algo
and O
they O
have O
shown O
signiﬁcant O
improvement O
on O
many O
graph O
classiﬁcation O
tasks O

Graph B-Algo
SAGE I-Algo
use O
LSTM B-Algo
as O
aggregation O
function O
in O
graph O
convolution O
however O
they O
preserves O
the O
localized O
property O

Set2Set B-Algo
is O
a O
graph O
algorithm O

SAGPool B-Algo
and O
gPool B-Algo
are O
typical O
score O
based O
pooling O
methods O

DiffPool B-Algo
is O
a O
representative O
pooling O
method O
where O
a O
large O
graph O
is O
downsampled O
to O
a O
small O
graph O
with O
pre O
ﬁxed O
size O
in O
a O
fully O
differentiable O
approach O

This O
is O
the O
expected O
behavior O
of O
GCNs B-Algo
by O
design O
to O
inherit O
merits O
of O
CNNs B-Algo
parameter O
sharing O
at O
different O
local O
area O
which O
can O
be O
regarded O
as O
a O
strong O
prior O
that O
local O
patterns O
are O
applicable O
everywhere O

gPool B-Algo
is O
a O
score O
based O
method O
used O
in O
the O
real O
world O

DiffPool B-Algo
is O
a O
fully O
differentiable O
graph O
pooling O
method O
introduced O

We O
follow O
the O
model O
architecture O
proposed O
in O
to O
make O
a O
fair O
comparison O
with O
the O
graph O
pooling O
layers O
replaced O
by O
compared O
methods O

For O
example O
he O
proposed O
a O
sequential O
learning O
framework O
based O
on O
long O
short O
term O
memory O
LSTM B-Algo
in O
which O
instant O
temporal O
dependencies O
are O
leveraged O

Convolution O
operation O
is O
integrated O
with O
LSTM B-Algo
and O
spatial O
correlations O
and O
temporal O
dependencies O
are O
both O
extracted O

External O
factors O
are O
further O
leveraged O
to O
improve O
the O
prediction O
accuracy O

DCRNN B-Algo
integrates O
graph O
convolution O
into O
gated O
recurrent O
units O
to O
predict O
traffic O
flows O
on O
the O
road O
network O

STGCN B-Algo
consists O
of O
several O
STConv B-Algo
blocks O
which O
are O
built O
with O
entirely O
convolutional O
layers O
to O
tackle O
prediction O
tasks O

For O
example O
he O
modeled O
taxi O
demand O
prediction O
as O
a O
time O
series O
prediction O
problem O
and O
an O
improved O
ARIMA B-Algo
is O
developed O
to O
predict O
taxi O
demands O
by O
leveraging O
the O
temporal O
dependencies O

He O
proposed O
an O
LSTM B-Algo
based O
sequential O
learning O
framework O
to O
model O
temporal O
dependencies O
of O
taxi O
demand O
in O
recent O
moments O

Furthermore O
he O
adopted O
CNN B-Algo
and O
LSTM B-Algo
to O
extract O
the O
spatial O
correlations O
among O
adjacent O
regions O
and O
temporal O
dependencies O
in O
a O
close O
period O
respectively O

External O
factors O
are O
further O
leveraged O
in O
to O
improve O
the O
prediction O
accuracy O

He O
try O
to O
incorporate O
the O
dependencies O
and O
external O
factors O
by O
using O
ﬁxed O
parameter O
matrixes O
learned O
during O
model O
training O

In O
word O
granularity O
many O
deep O
learning O
based O
sentence O
semantic O
matching O
models O
have O
been O
proposed O
such O
as O
DeepMatchtree B-Algo
ARC B-Algo
MatchPyramid B-Algo
MatchSRNN B-Algo
etc O

Eventually O
more O
and O
more O
researchers O
turn O
to O
design O
semantic O
matching O
strategy O
combing O
word O
and O
phrase O
granularity O
such O
as O
MultiGranCNN B-Algo
MVLSTM B-Algo
MPCM B-Algo
BiMPM B-Algo
DIIN B-Algo

For O
example O
CNNs B-Algo
have O
achieved O
great O
performance O

Yin O
et O
al O
propose O
MultiGranCNN B-Algo
to O
ﬁrst O
obtain O
text O
features O
on O
granularity O
such O
as O
words O
phrases O
and O
sentences O
and O
then O
concatenate O
these O
text O
features O
and O
calculate O
the O
similarity O
between O
the O
two O
sentences O

propose O
MultiGranCNN B-Algo
to O
ﬁrst O
obtain O
text O
features O
on O
diﬀerent O
granularity O
such O
as O
words O
phrases O
and O
sentences O
and O
then O
concatenate O
these O
text O
features O
and O
calculate O
the O
similarity O
between O
the O
two O
sentences O

Wan O
et O
al O
propose O
MVLSTM B-Algo
similar O
to O
MultiGranCNN B-Algo
which O
can O
capture O
long O
distance O
and O
short O
distance O
dependencies O
simultaneously O

MIX B-Algo
is O
a O
multi O
channel O
model O
for O
text O
matching O
with O
additional O
attention O
mechanisms O
on O
sentences O
and O
semantic O
features O

Kriz O
et O
al O
present O
a O
customized O
loss O
function O
to O
replace O
the O
standard O
cross O
entropy O
during O
training O
which O
takes O
the O
complexity O
of O
content O
words O
into O
account O

Some O
unsupervised O
matching O
methods O
based O
on O
WMD B-Algo
has O
been O
introduced O


Some O
unsupervised O
matching O
methods O
based O
on O
CNN B-Algo
BiLSTM B-Algo
BiMPM B-Algo
and O
DFF B-Algo
is O
used O

BiMPM B-Algo
is O
a O
bilateral O
multi O
perspective O
matching O
model O
which O
utilizes O
BiLSTM B-Algo
to O
learn O
the O
sentence O
representation O
and O
implements O
four O
strategies O
to O
match O
the O
sentences O
from O
diﬀerent O
perspectives O

DFF B-Algo
is O
a O
deep O
feature O
fusion O
model O
for O
sentence O
representation O
which O
is O
integrated O
into O
the O
popular O
deep O
architecture O
for O
SSM B-Algotask O

Clustering O
based O
methods O
aim O
at O
density O
estimation O
of O
data O
points O
and O
usually O
adopt O
a O
two O
step O
strategy O
that O
performs O
dimensionality O
reduction O
ﬁrstly O
and O
then O
clustering O

This O
denotes O
the O
concatenate O
operation O

Inspired O
by O
DAGMM B-Algo
a O
sub O
network O
consists O
of O
several O
fully O
connected O
layers O
is O
utilized O
which O
takes O
the O
reconstruction O
error O
preserved O
low O
dimentional O
embedding O
as O
input O
to O
estimate O
the O
mixture O
membership O
for O
each O
sample O

DSEBM B-Algo
is O
a O
deep O
energy O
based O
model O
which O
aims O
to O
accumulate O
the O
energy O
across O
the O
layers O

DSEBM B-Algo
and O
DSEBM O
are O
utilized O
in O
by O
taking O
the O
energy O
and O
reconstruction O
error O
as O
the O
anomaly O
score O
respectively O

DAGMM B-Algo
is O
an O
autoencoder O
based O
method O
for O
anomaly O
detection O
which O
consists O
of O
a O
compression O
network O
for O
dimension O
reduction O
and O
an O
estimate O
network O
to O
perform O
density O
estimation O
under O
the O
Gaussian O
Mixture O
Model O

AnoGAN B-Algo
is O
an O
anomaly O
detection O
algorithm O
based O
on O
GAN B-Algo
which O
trains O
a O
DCGAN B-Algo
to O
recover O
the O
representation O
of O
each O
data O
sample O
in O
the O
latent O
space O
during O
prediction O

ALAD B-Algo
is O
based O
on O
GANs B-Algo
for O
anomaly O
detection O
by O
deriving O
adversarially O
learned O
features O
and O
uses O
reconstruction O
errors O
based O
on O
the O
learned O
features O
to O
determine O
if O
a O
data O
sample O
is O
anomalous O

Speciﬁcally O
we O
take O
the O
low O
dimensional O
embeddings O
of O
samples O
learned O
by O
DAGMM B-Algo
and O
CADGMM B-Algo
as O
the O
inputs O

CRH B-Algo
is O
a O
popular O
truth O
discovery O
based O
model O
for O
numerical O
data O

CATD B-Algo
is O
an O
extension O
of O
CRH B-Algo
that O
learns O
a O
conﬁdence O
interval O
over O
user O
reliabilities O
to O
handle O
data O
skewness O

TrustAnswer B-Algo
modeled O
semantic O
similarity O
between O
comments O
by O
representing O
each O
comment O
with O
embeddings O
of O
its O
key O
phrase O

In O
general O
there O
is O
a O
drop O
in O
performance O
for O
all O
models O
on O
this O
metric O
because O
it O
is O
harder O
to O
predict O
upvotes O
as O
they O
are O
inherently O
noisy O

Faitcrowd B-Algo
assumes O
an O
objective O
truth O
in O
the O
answer O
set O
and O
uses O
a O
probabilistic O
generative O
model O
to O
perform O
ﬁne O
grained O
truth O
discovery O

CQARank B-Algo
leverages O
voting O
information O
as O
well O
as O
user O
history O
and O
estimates O
user O
interests O
and O
expertise O
on O
diﬀerent O
topics O

Text O
based O
deep O
learning O
models O
learn O
an O
optimal O
representation O
of O
question O
and O
answer O
pairs O
to O
identify O
the O
most O
relevant O
answer O

In O
SemEval O
task O
on O
CQA O
Nakov O
et O
al O
developed O
a O
task O
to O
recommend O
related O
answers O
to O
a O
new O
question O
in O
the O
forum O

Further O
the O
proposed O
model O
in O
uses O
similarity O
matrices O
which O
are O
inefficient O
in O
both O
memory O
and O
computation O

Further O
individually O
on O
these O
sub O
graphs O
we O
employ O
a O
multi O
layer O
graph O
mechanism O
GAT B-Algo
to O
construct O
ﬁrst O
level O
view O
wise O
embeddings O

NeuACF B-Algo
is O
a O
state O
of O
the O
art O
model O
for O
top O
N O
heterogeneous O
recommendation O
setting O

HERec B-Algo
is O
a O
recently O
proposed O
two O
stage O
approach O
for O
heterogeneous O
recommendation O
setting O

NeuMF B-Algo
is O
one O
of O
the O
state O
of O
the O
art O
models O
for O
rating O
only O
top O
N O
recommendation O
setting O

MF I-Algo
is O
a O
standard O
and O
well O
known O
baseline O
for O
the O
recommendation O
task O

BPR B-Algo
is O
a O
standard O
baseline O
for O
the O
top O
N O
recommendation O
setting O

FMG B-Algo
is O
another O
recently O
proposed O
model O
that O
utilizes O
commuting O
matrices O
learned O
from O
meta O
graph O
based O
strategy O

Since O
it O
has O
been O
shown O
in O
that O
NeuACF B-Algo
outperforms O
FMG B-Algo
we O
omit O
this O
from O
the O
comparison O

Early O
CF B-Algo
techniques O
are O
mainly O
based O
on O
matrix O
factorization O
models O
BPR B-Algo
and O
MF I-Algo
and O
their O
extensions O

For O
instance O
NeuMF B-Algo
combines O
MF I-Algo
with O
a O
perceptron B-Algo
to O
learn O
better O
representations O
for O
users O
and O
items O

For O
instance O
HeteRec B-Algo
uses O
metapath O
based O
similarity O
construction O

Besides O
SemRec B-Algo
employs O
weighted O
meta O
paths O
to O
prioritize O
and O
personalize O
user O
preferences O
on O
paths O

In O
terms O
of O
utilizing O
multiple O
views O
aspects O
for O
the O
items O
our O
work O
is O
related O
to O
NeuACF B-Algo
MCRec B-Algo
HERec B-Algo
KGAT B-Algo
and O
FMG B-Algo

For O
instance O
NeuACF B-Algo
follows O
a O
two O
stage O
approach O
in O
the O
ﬁrst O
stage O
it O
constructs O
similarity O
matrices O

KGAT B-Algo
incorporates O
information O
from O
the O
knowledge O
graph O
using O
graph O
neural O
networks O

In O
place O
of O
meta O
paths O
FMG B-Algo
proposes O
meta O
graphs O
for O
extracting O
knowledge O

Further O
he O
proposes O
HERec B-Algo
that O
fuses O
meta O
path O
based O
embeddings O

Wang O
et O
al O
adopt O
GCNs B-Algo
to O
embed O
entities O
with O
the O
one O
hot O
representations O
of O
the O
attributes O

They O
use O
MultiKE B-Algo
to O
embed O

We O
compare O
several O
existing O
methods O
MuGNN B-Algo
Learns O
the O
structure O
embeddings O
by O
a O
multi O
channel O
GNNs B-Algo

BootEA B-Algo
Is O
a O
bootstrap O
method O
that O
ﬁnds O
new O
alignments O
by O
performing O
a O
maximal O
matching O
between O
the O
structure O
embeddings O
of O
the O
entities O

JAPE B-Algo
Leverages O
the O
attributes O
and O
the O
type O
of O
values O
to O
reﬁne O
the O
struc O
ture O
embeddings O

GCNs B-Algo
Learns O
the O
structure O
embeddings O
by O
GCNs B-Algo
and O
use O
the O
one O
hot O
representation O
of O
all O
the O
attributes O
as O
the O
initial O
input O
of O
an O
entity O

As O
KDCoE B-Algo
leverage O
the O
descriptions O
of O
entities O

In O
particular O
a O
LSTM B-Algo
model O
is O
used O
to O
encode O
long O
term O
preferences O
while O
short O
term O
dependencies O
existing O
in O
pair O
relations O
among O
items O
are O
computed O
based O
on O
the O
intermedia O
hidden O
states O
of O
LSTM B-Algo
on O
both O
individual O
level O
and O
union O
level O

Recently O
Deep O
learning O
based O
models O
have O
achieved O
signiﬁcant O
eﬀectiveness O
in O
long O
term O
temporal O
information O
modeling O
including O
multi O
layer O
perceptron B-Algo
based O
MLP B-Algo
based O
models O
CNN B-Algo
based O
models O
and O
RNN B-Algo
based O
models O

However O
RNN B-Algo
can O
be O
difficult O
to O
trained O
due O
to O
the O
vanishing O
gradient O
problem O
but O
advances O
such O
as O
LSTM B-Algo
has O
enabled O
RNN B-Algo
to O
be O
successful O

The O
SGNS B-Algo
generate O
item O
representations O
by O
exploiting O
the O
sequence O
of O
interactions O
between O
users O
and O
items O

We O
compare O
with O
three O
baselines O
BPRMF B-Algo
is O
a O
widely O
used O
matrix O
factorization O
method O
for O
sequential O

TranRec B-Algo
models O
users O
as O
translation O
vectors O
operating O
on O
item O
sequences O
for O
sequential O
RNN B-Algo
based O
model O
i O
e O
GRU4Rec B-Algo
uses O
FPMC B-Algo

LOF B-Algo
is O
based O
on O
proximity O
between O
objects O

Irrelevant O
variables O
have O
no O
or O
very O
little O
contribution O
to O
the O
anomaly O
score O
and O
even O
have O
a O
negative O
impact O
on O
the O
eﬀectiveness O

COMBN B-Algo
is O
a O
typical O
method O
falling O
in O
this O
category O

MB B-Algo
is O
a O
fundamental O
concept O
in O
the O
bayesian O
theory O

Markov B-Algo
Blankets B-Algo
are O
deﬁned O
in O
the O
context O
of O
a O
Bayesian O
network O
BN B-Algo
A O
detailed O
study O
on O
the O
impact O
of O
diﬀerent O
combination O
functions O
on O
the O
performance O
of O
anomaly O
detection O
can O
be O
found O
in O

For O
the O
LoPAD B-Algo
algorithm O
we O
use O
the O
fast O
IAMB B-Algo
to O
learn O

For O
estimating O
expected O
values O
we O
adopt O
CART B-Algo
regression I-Algo
tree I-Algo
to O
enable O
the O
LoPAD B-Algo
algorithm O
to O
cope O
with O
both O
linear O
and O
non O
linear O
dependency O

The O
comparison O
methods O
include O
dependency O
based O
methods O
ALSO B-Algo
and O
COMBN B-Algo
and O
proximity O
based O
methods O
MBOM B-Algo
LoPAD B-Algo
iForest B-Algo
and O
LOF B-Algo

For O
a O
fair O
comparison O
both O
LoPAD B-Algo
and O
ALSO B-Algo
adopt O
CART B-Algo
regression I-Algo
tree I-Algo
with O
bagging O

Apart O
from O
dependency O
based O
approach O
the O
mainstream O
of O
anomaly O
detection O
methods O
is O
proximity O
based O
such O
as O
LOF B-Algo

To O
address O
this O
problem O
some O
subspace O
based O
methods O
are O
proposed O
to O
detect O
anomalies O
based O
on O
the O
proximity O
with O
respect O
to O
subsets O
of O
variables O
i O
e O
subspaces O

For O
example O
with O
MBOM B-Algo
a O
subspace O
contains O
a O
variable O
and O
LOF B-Algo
is O
used O
to O
evaluate O
anomalousness O
in O
each O
such O
a O
subspace O

Another O
novel O
subspace O
based O
anomaly O
detection O
method O
iForest B-Algo
randomly O
selects O
subsets O
of O
variables O
as O
subspaces O
which O
shows O
good O
performance O
in O
both O
eﬀectiveness O

For O
example O
proposed O
a O
model O
PDC B-Algo
that O
used O
STN B-Algo
to O
crop O
body O
regions O
based O
on O
pre O
deﬁned O
centers O

He O
achieved O
the O
more O
precise O
feature O
alignment O
based O
on O
their O
proposed O
network O
called O
AACN B-Algo
and O
further O
improved O
the O
performance O
of O
identiﬁcation O

With O
the O
rapid O
development O
of O
instance O
segmentation O
based O
on O
deep O
learning O
methods O
such O
as O
CNN B-Algo
and O
FCN B-Algo
now O
we O
can O
easily O
obtain O
high O
quality O
pedestrian O
masks O
which O
can O
be O
used O
in O
person O
reidentiﬁcation O

In O
this O
paper O
we O
choose O
CNN B-Algo
to O
predict O
the O
masks O
due O
to O
its O
high O
accuracy O
and O
ﬂexibility O

Following O
the O
original O
article O
of O
CNN B-Algo
we O
set O
hyper O
parameters O
as O
suggested O
by O
existing O
Faster O
RCNN B-Algo
work O
and O
deﬁne O
the O
loss O

In O
this O
module O
we O
use O
four O
ResNet B-Algo
networks O
to O
extract O
the O
features O

The O
SpindleNet B-Algo
learns O
from O
DLPAR B-Algo
MSCAN B-Algo

The O
SVDNet B-Algo
and O
the O
PAN B-Algo
PAR B-Algo
DPFL B-Algo
DaF B-Algo
and O
the O
null O
space O
semi O
supervised O
learning O
method O
NFST B-Algo
are O
pose O
irrelevant O

For O
example O
when O
a O
young O
lady O
go O
home O
from O
outside O
the O
air O
conditioning O
and O
audio O
could O
select O
a O
gender O
age O
aware O
response O
air O
conditioning O
temperature O
and O
music O
from O
many O
possible O
candidates O
to O
make O
the O
user O
more O
comfortable O

They O
mostly O
come O
from O
Facebook O
Twitters O
microblogs O
YouTube O
web O
search O
queries O
social O
networking O
chats O
and O
forum O
posts O

For O
example O
he O
proposed O
a O
SNE B-Algo
model O
that O
use O
shared O
embedding O
to O
leverages O
the O
potential O
correlations O
for O
multi O
task O
learning O
by O
concatenating O
structured O
label O

He O
proposed O
a O
SNE B-Algo
model O
that O
use O
shared O
embedding O
to O
leverages O
the O
potential O
correlations O
for O
multi O
task O
learning O
by O
concatenating O
structured O
label O

Raehyun O
et O
al O
proposed O
an O
ETN B-Algo
model O
that O
shares O
user O
representations O
at O
the O
bottom O
and O
converts O
them O
to O
task O
speciﬁc O
representations O
using O
a O
linear O
transformation O

Considering O
that O
the O
pedometer O
data O
is O
a O
kind O
of O
temporal O
data O
we O
adopt O
the O
most O
popular O
sequence O
learning O
model O
of O
LSTM B-Algo
as O
the O
backbone O
of O
each O
embedding O
branches O

Therefore O
we O
combine O
forward O
left O
to O
right O
and O
backward O
right O
to O
left O
recurrent O
to O
build O
a O
LSTM B-Algo
BiLSTM B-Algo

Adam B-Algo
is O
used O
as O
the O
optimization O
algorithm O
and O
the O
mini O
batch O
size O
is O

Traditional O
methods O
utilize O
time O
series O
models O
such O
as O
ARIMA B-Algo
and O
its O
variants O
to O
predict O
trafﬁc O

There O
are O
two O
ways O
of O
utilizing O
the O
spatial O
relationships O
in O
literature O
Treating O
the O
whole O
city O
as O
an O
image O
a O
two O
dimensional O
matrix O
and O
applying O
CNN B-Algo
or O
ConvLSTM B-Algo
directly O
to O
this O
image O
to O
capture O
relationships O
among O
all O
regions O

However O
previous O
works O
either O
don O
t O
take O
these O
external O
features O
into O
account O
or O
directly O
map O
external O
features O
to O
future O
passenger O
demand O
which O
can O
lead O
to O
large O
biases O
because O
the O
inﬂuence O
of O
external O
factors O
is O
not O
uniform O
to O
all O
regions O

Notation O
Region O
We O
utilize O
the O
road O
networks O
based O
partition O
to O
divide O
the O
entire O
city O
into O
blocks O
as O
it O
is O
more O
ﬂexible O
and O
can O
integrate O
semantic O
meanings O
into O
regions O

The O
state O
of O
the O
art O
methods O
usually O
map O
external O
features O
to O
the O
value O
of O
the O
passenger O
demand O
directly O
which O
can O
result O
in O
signiﬁcant O
errors O
and O
thus O
doesn O
t O
make O
the O
best O
use O
of O
external O
features O

XGBoost B-Algo
XGBoost B-Algo
is O
a O
boosting O
tree O
based O
machine O
learning O
method O
which O
is O
used O
to O
achieve O
state O
of O
the O
art O
results O
on O
many O
data O
mining O
challenges O

DMVSTNet B-Algo
is O
a O
state O
of O
the O
art O
method O
for O
predict O
passenger O
demand O

As O
described O
in O
Section O
DMVSTNet B-Algo
can O
only O
be O
used O
when O
the O
city O
is O
partitioned O
to O
grids O

Nearest O
Similar O
with O
DMVSTNet B-Algo
it O
only O
considers O
spatially O
nearby O
regions O
to O
capture O
their O
spatial O
correlations O
PoI O
Select O
correlated O
regions O
by O
PoI O
similarity O
Order O
Select O
correlated O
regions O
by O
historical O
demand O
series O
similarity O
All O
Similar O
with O
DeepST B-Algoit O
captures O
the O
spatial O
correlations O
within O
the O
whole O
city O

Luis O
Moreira O
Matias O
et O
al O
combined O
three O
time O
series O
forecasting O
techniques O
Time O
Varying O
Poisson O
Model O
Weighted O
Time O
Varying O
Poisson O
Model O
ARIMA B-Algo
model O
to O
arrive O
at O
a O
prediction O

Rose O
Yu O
et O
al O
proposed O
to O
use O
LSTM B-Algo
network O
to O
capture O
the O
temporal O
relationship O
in O
historical O
observations O
and O
used O
auto O
encoder O
to O
process O
static O
features O

Yao O
et O
al O
further O
designed O
local O
CNN B-Algo
to O
extract O
spatial O
relationship O
within O
surrounding O
regions O
and O
construct O
a O
weighted O
graph O
to O
represent O
similarity O
among O
regions O

further O
designed O
local O
CNN B-Algo
to O
extract O
spatial O
relationship O
within O
surrounding O
regions O
and O
construct O
a O
weighted O
graph O
to O
represent O
similarity O
among O
regions O

Such O
a O
side O
information O
may O
be O
retrieved O
from O
social O
networks O
and O
may O
include O
user O
demographic O
information O
item O
attributes O
and O
context O
information O

As O
the O
auxiliary O
data O
is O
useful O
for O
the O
recommendation O
systems O
desirable O
to O
model O
and O
utilize O
heterogeneous O
and O
complex O
data O
types O
in O
recommendation O
systems O

employ O
the O
KGE B-Algo
model O
to O
represent O
users O
movies O
and O
movie O
attributes O

GeoSAGE B-Algo
exploited O
co O
occurrence O
patterns O
with O
contents O
of O
spatial O
items O

proposed O
entity2rec B-Algo
to O
capture O
a O
user O
item O
relatedness O
from O
KGEs B-Algo
with O
the O
goal O
of O
generating O
top O
k O
item O
recommendations O

adopts O
KGE B-Algo
to O
model O
the O
side O
information O
recommendation O
system O

Finally O
noteworthy O
is O
the O
family O
of O
models O
such O
as O
GCN B-Algo
GraphSAGE B-Algo
GCN O
kernel B-Algobased O
CKN B-Algo
as O
well O
as O
generic O
graph O
embedding O
approaches O
such O
as O
DeepWalk B-Algo
and O
Node2Vec B-Algo
which O
all O
have O
the O
capacity O
to O
model O
graph O
related O
tasks O

We O
apply O
TransR B-Algo
to O
our O
recommendation O
model O

PMF B-Algo
is O
a O
classic O
factorization O
model O
that O
explicitly O
factorizes O
the O
rating O
matrix O
into O
two O
low O
rank O
matrices O

GeoMF B-Algo
is O
a O
weighted O
matrix O
factorization O
model O
for O
POI O
recommendations O

RankGeoFM B-Algo
is O
a O
ranking O
based O
geographical O
factorization O
model O
in O
which O
the O
check O
in O
frequency O
characterizes O
users O
visiting O
preference O
and O
the O
factorization O
is O
learnt O
by O
ranking O

GeoSoCa B-Algo
model O
extends O
the O
kernel B-Algodensity O
estimation O
by O
applying O
an O
adaptive O
bandwidth O
learnt O
from O
the O
user O
check O
in O
data O

STLDA B-Algo
is O
a O
latent O
class O
probabilistic O
generative O
Spatio O
Temporal O
LDA B-Algomodel O
which O
learns O
the O
region O
dependent O
personal O
interests O
according O
to O
the O
contents O

TransRec B-Algo
is O
the O
translation O
based O
recommendation O
approach O
proposed O
in O
which O
embeds O
items O
into O
a O
translation O
space O
and O
models O
users O
via O
a O
translation O
vector O

STA B-Algo
is O
a O
spatio O
temporal O
context O
aware O
and O
translation O
based O
recommendation O
model O

Most O
of O
these O
work O
including O
VGAE B-Algo
and O
Graph2Gauss B-Algo
focuses O
on O
modelling O
the O
uncertainty O
of O
the O
node O
embeddings O
by O
representing O
the O
nodes O
with O
a O
probabilistic O
distribution O
in O
the O
embedding O
space O

DeepWalk B-Algo
and O
node2vec B-Algo
learn O
node O
embeddings O
from O
random O
walk O
sequences O
with O
a O
technique O
similar O
to O
Skip O
Gram O

DVNE B-Algo
uses O
an O
auto O
encoder O
architecture O
to O
encode O
and O
reconstruct O
the O
graph O
structure O

TADW B-Algo
incorporates O
text O
attributes O
and O
graph O
structure O
with O
low O
rank O
matrix O
factorization O

GraphSAGE B-Algo
is O
a O
CNN B-Algo
based O
technique O
that O
samples O
and O
aggregates O
neighbouring O
node O
attributes O

VGAE B-Algo
is O
a O
graph O
convolution O
network O
GCN B-Algo
method O
which O
aggregates O
neighbouring O
attributes O

In O
contrast O
Graph2Gauss B-Algo
VGAE B-Algo
DVNE B-Algo
and O
GLACE B-Algo
capture O
the O
uncertainty O
of O
graph O
structure O
by O
learning O
node O
embeddings O
as O
Gaussian O
distributions O

Since O
ˆP O
and O
P O
are O
discrete O
probability O
distributions O
we O
deﬁne O
structural O
loss O
using O
KL O
divergence O

For O
regularization O
of O
Ls O
instead O
of O
regularizing O
mean O
and O
covariance O
functions O
separately O
RASE B-Algo
uses O
the O
strategy O
similar O
to O
minimizing O
KL O
divergence O
between O
the O
learned O
Gaussian O
representation O
and O
the O
standard O
normal O
distribution O

Different O
from O
RASE B-Algo
Graph2Gauss B-Algo
does O
not O
regularize O
the O
Gaussian O
functions O

To O
optimize O
Ls O
we O
employ O
the O
negative O
sampling O
approach O
and O
sample O
K O
negative O
edges O
for O
each O
edge O
in O
the O
training O
batch O

node2vec B-Algo
is O
a O
random O
walk O
based O
node O
embedding O
method O
that O
maximizes O
the O
likelihood O
of O
preserving O
nodes O
neighbourhood O

VGAE B-Algo
is O
an O
attributed O
GCN B-Algo
based O
embedding O
method O
which O
implements O
an O
auto O
encoder O
model O
with O
Gaussian O
node O
embeddings O

Graph2Gauss B-Algo
G2G B-Algo
is O
an O
attributed O
embedding O
method O
which O
represents O
each O
node O
as O
a O
Gaussian O
and O
preserves O
the O
graph O
structure O
based O
on O
a O
ranking O
scheme O
of O
multiple O
neighbouring O
hops O

We O
report O
micro O
and O
macro O
F1 O
scores O
which O
have O
been O
widely O
used O
in O
multi O
class O
classiﬁcation O
evaluation O

Furthermore O
the O
square O
exponential O
loss O
function O
used O
for O
pair O
wise O
ranking O
in O
both O
G2G B-Algo
and O
DVNE B-Algo
does O
not O
have O
a O
ﬁxed O
margin O
and O
pushes O
the O
distance O
of O
the O
negative O
edges O
to O
inﬁnity O
with O
an O
exponentially O
decreasing O
force O

Examples O
include O
studies O
on O
link O
prediction O
and O
graph O
clustering O
or O
node O
classiﬁcation O
which O
is O
the O
particular O
focus O
of O
this O
study O

In O
recent O
studies O
neural O
network O
classiﬁers O
are O
widely O
used O
for O
both O
types O
of O
methods O
due O
to O
their O
performance O
and O
ﬂexibility O

A O
well O
established O
example O
is O
the O
GCN B-Algo
a O
semi O
supervised O
model O
that O
uses O
the O
whole O
adjacency O
matrix O
as O
a O
ﬁlter O
in O
each O
neural O
network O
layer O

We O
formulate O
graph O
sparsiﬁcation O
as O
an O
optimization O
problem O
which O
we O
eﬃciently O
solve O
via O
the O
ADMM B-Algo

We O
also O
show O
that O
node O
classiﬁcation O
performance O
using O
these O
sparsiﬁed O
graphs O
can O
be O
better O
or O
comparable O
to O
when O
original O
graphs O
are O
used O
in O
GCN B-Algo
DeepWalk B-Algo
and O
GraphSAGE B-Algo

Another O
is O
DUIF B-Algo
proposed O
by O
Geng O
et O
al O
which O
uses O
a O
hierarchical O
softmax O
for O
forward O
propagation O
to O
maximize O
modularity O

which O
uses O
a O
hierarchical O
softmax O
for O
forward O
propagation O
to O
maximize O
modularity O

For O
example O
Gilmer O
et O
al O
develop O
a O
message O
passing O
neural O
network O
to O
embed O
any O
existing O
GCN B-Algo
model O
into O
a O
message O
passing O
the O
inﬂuence O
of O
neighbors O
and O
readout O
pattern O

develop O
a O
message O
passing O
neural O
network O
to O
embed O
any O
existing O
GCN B-Algo
model O
into O
a O
message O
passing O
the O
inﬂuence O
of O
neighbors O
and O
readout O
pattern O

which O
aims O
to O
identity O
the O
backbone O
of O
a O
network O
that O
preserves O
structural O
and O
hierarchical O
information O
in O
the O
original O
graph O

xk O
the O
forward O
model O
i O
e O
output O
of O
a O
two O
layered O
graph O
convolutional O
network O
GCN B-Algo
as O
formulated O
by O
Kipf O
and O
Welling O

ADMM B-Algo
is O
a O
powerful O
method O
for O
solving O
convex O
optimization O
problems O

When O
we O
apply O
ADMM B-Algo
to O
this O
problem O
we O
alternately O
update O
the O
variables O

Time O
Complexity O
Analysis O
The O
GCN B-Algo
training O
time O
complexity O
is O
O O
L O
A0 O
F O
LN O
F O
where O
L O
is O
the O
number O
of O
layers O
N O
is O
the O
number O
of O
nodes O
A0 O
is O
the O
number O
of O
non O
zeros O
in O
an O
adjacency O
matrix O
and O
F O
is O
the O
number O
of O
features O

The O
SS B-Algo
is O
the O
state O
of O
the O
art O
spectral O
sparsiﬁer O
which O
sparsiﬁes O
graphs O
in O
near O
linear O
time O

In O
SS B-Algo
we O
use O
the O
default O
suggested O
parameters O
for O
spectral O
sparsiﬁer O

Keywords O
Graph B-Algo
neural O
networks O
Attention O
mechanism O
Self O
training O
Soft O
labels O
Semi O
supervised O
classiﬁcation O
Introduction O
In O
recent O
years O
graph O
convolutional O
neural O
networks O
GCNs B-Algo
which O
can O
learn O
from O
graph O
structured O
data O
have O
attracted O
much O
attention O

The O
generated O
node O
representations O
can O
then O
be O
used O
as O
input O
to O
a O
prediction O
layer O
for O
various O
downstream O
tasks O
such O
as O
node O
classiﬁcation O
graph O
classiﬁcation O
link O
prediction O
and O
social O
recommendation O

Graph B-Algo
attention O
networks O
GAT B-Algo
which O
is O
one O
of O
the O
most O
representative O
GCNs B-Algo
learns O
the O
weights O
for O
neighborhood O
aggregation O
via O
self O
attention O
mechanism O
and O
achieves O
promising O
performance O
on O
semi O
supervised O
node O
c O
cid O
Springer O
Nature O
Switzerland O
AG O
H O
W O
Lauw O
et O
al O
Eds O

And O
graph O
Laplacian O
regularizer O
is O
most O
commonly O
used O
in O
Y O
Wang O
et O
al O
previous O
studies O
including O
label O
propagation O
local O
and O
global O
consistency O
regularization O
manifold O
regularization O
and O
deep O
semi O
supervised O
embedding O

previous O
studies O
including O
label O
propagation O
local O
and O
global O
consistency O
regularization O
manifold O
regularization O
and O
deep O
semi O
supervised O
embedding O

Recently O
graph O
embedding O
based O
methods O
inspired O
by O
the O
skip B-Algogram O
model O
has O
attracted O
much O
attention O

DeepWalk B-Algo
samples O
node O
sequences O
via O
uniform O
random O
walks O
on O
the O
network O
and O
then O
learns O
embeddings O
via O
the O
prediction O
of O
the O
local O
neighborhood O
of O
nodes O

Afterward O
a O
large O
number O
of O
works O
including O
LINE B-Algo
and O
node2vec B-Algo
extend O
DeepWalk B-Algo
with O
more O
sophisticated O
random O
walk O
schemes O

Planetoid B-Algo
alleviates O
this O
by O
incorporating O
label O
information O
into O
the O
process O
of O
learning O
embeddings O

Recently O
graph O
convolutional O
neural O
networks O
GCNs B-Algo
have O
been O
successfully O
applied O
in O
many O
applications O

He O
used O
polynomial O
spectral O
filters O
to O
reduce O
the O
computational O
cost O

Kipf O
Welling O
then O
simpliﬁed O
the O
previous O
method O
by O
using O
a O
linear O
filter O
to O
operate O
one O
hop O
neighboring O
nodes O

Wu O
et O
al O
used O
graph O
wavelet O
to O
implement O
localized O
SVM B-Algo

Xu O
et O
al O
used O
a O
heat O
kernel B-Algoto O
enhance O
low O
frequency O
ﬁlters O
and O
enforce O
smoothness O
in O
the O
signal O
variation O
on O
the O
graph O

GraphSAGE B-Algo
performs O
various O
aggregators O
such O
as O
meanpooling O
over O
a O
ﬁxed O
size O
neighborhood O
of O
each O
node O

Monti O
et O
al O
provided O
a O
uniﬁed O
framework O
that O
generalized O
various O
GCNs B-Algo

provided O
a O
uniﬁed O
framework O
that O
generalized O
various O
GCNs B-Algo

Instead O
of O
ﬁxed O
weight O
for O
GAT B-Algo
adopts O
attention O
mechanisms O
to O
learn O
the O
relative O
weights O
between O
two O
connected O
nodes O

He O
generalized O
GAT B-Algo
to O
learn O
representations O
of O
heterogeneous O
networks O
using O
meta O
paths O

We O
use O
a O
multi O
layer O
GCN B-Algo
to O
aggregate O
the O
features O
of O
neighboring O
nodes O
We O
compare O
against O
several O
traditional O
graph O
based O
semi O
supervised O
classiﬁcation O
methods O
including O
manifold O
regularization O
ManiReg B-Algo
semi O
supervised O
embedding O
SemiEmb B-Algo
label O
propagation O
LP B-Algo
graph O
embeddings O
DeepWalk B-Algo
iterative O
classiﬁcation O
algorithm O
ICA B-Algo
and O
Planetoid B-Algo

We O
adopt O
the O
Adam B-Algo
optimizer O
for O
parameter O
optimization O
with O
initial O
learning O
rate O
as O
and O
weight O
decay O

Results O
on O
Data O
Splits O
Following O
Shchur O
et O
al O
we O
also O
further O
validate O
the O
eﬀectiveness O
and O
robustness O
of O
SLGAT B-Algo
on O
random O
data O
splits O

we O
also O
further O
validate O
the O
eﬀectiveness O
and O
robustness O
of O
SLGAT B-Algo
on O
random O
data O
splits O

We O
compare O
SLGAT B-Algo
with O
other O
most O
related O
competitive O
baselines O
including O
GCN B-Algo
and O
GAT B-Algo
on O
those O
random O
data O
splits O
We O
run O
each O
method O
with O
random O
seeds O
on O
each O
data O
split O
and O
report O
the O
overall O
mean O
accuracy O
in O
Table O

The O
reason O
behind O
such O
phenomenon O
is O
still O
under O
investigation O
we O
presume O
that O
it O
is O
due O
to O
the O
label O
sparsity O
of O
Pubmed O
The O
similar O
phenomenon O
is O
reported O
in O
that O
GAT B-Algo
has O
little O
improvement O
on O
Pubmed O
compared O
to O
GCN B-Algo

These O
approaches O
either O
treat O
all O
social O
relations O
equally O
or O
make O
use O
of O
a O
predeﬁned O
similarity O
function O

In O
particular O
Chen O
et O
al O
presented O
a O
social O
attentional O
memory O
network O
which O
utilizes O
an O
attention O
based O
memory O
module O
to O
learn O
the O
relation O
vectors O
for O
user O
friend O
pairs O

presented O
a O
social O
attentional O
memory O
network O
which O
utilizes O
an O
attention O
based O
memory O
module O
to O
learn O
the O
relation O
vectors O
for O
user O
friend O
pairs O

Further O
proposed O
ATRank B-Algo
which O
models O
heterogeneous O
user O
behaviour O
using O
an O
attention O
model O
and O
captures O
the O
interaction O
between O
users O
using O
self O
attention O

Motivated O
by O
the O
success O
of O
GAT B-Algo
we O
propose O
SoRecGAT B-Algo

In O
this O
work O
we O
use O
cross O
entropy O
loss O
with O
negative O
sampling O
strategy O
for O
training O
the O
model O

Node O
Features O
Initial O
embeddings O
of O
graph O
nodes O
before O
using O
multi O
head O
attention O
layers O
are O
obtained O
using O
skip B-Algogram O
technique O

We O
select O
representatives O
for O
each O
group O
and O
detail O
them O
below O
SAMN B-Algo
is O
a O
state O
of O
the O
art O
model O
for O
top O
N O
social O
recommendation O
setting O

It O
extends O
PMF B-Algo
for O
social O
recommendation O
in O
the O
second O
stage O

SBPR B-Algo
is O
a O
state O
of O
the O
model O
for O
the O
top O
N O
recommendation O
setting O

It O
TrustSVD B-Algo
extends O
the O
model O
to O
social O
recommendation O

NeuMF B-Algo
is O
a O
recently O
proposed O
state O
of O
the O
art O
model O
for O
rating O
only O
setting O

GMF B-Algo
is O
a O
generalization O
of O
matrix O
factorization O
and O
proposed O
as O
a O
part O
of O
BPR B-Algo
is O
a O
standard O
baseline O
for O
top O
N O
ranking O
setting O

It O
optimizes O
the O
MF B-Algo
is O
a O
standard O
and O
widely O
adopted O
baseline O
for O
collaborative O
ﬁltering O

RecGAT B-Algo
is O
a O
special O
case O
of O
our O
model O
which O
uses O
only O
user O
item O
interaction O
NeuMF B-Algo

Our O
implementation O
is O
available O
at O
https O
github O
com O
SoRecGAT B-Algo

We O
use O
the O
dropout O
regularizer O
and O
adopt O
RMSProp B-Algo
with O
mini O
batch O
for O
optimization O

He O
et O
al O
proposed O
NeuMF B-Algo
that O
marries O
multi O
layer O
perceptron B-Algo
with O
generalized O
matrix O
factorization O
model O
to O
get O
the O
best O
of O
both O
MF B-Algo
and O
neural I-Algo
network I-Algo
world O

For O
instance O
SocialMF B-Algo
considers O
social O
influence O
by O
trust O
propagation O
mechanism O
SoReg B-Algo
incorporates O
social O
connections O
as O
regularizers O
to O
user O
representations O
learned O
from O
user O
item O
ratings O
and O
TrustSVD B-Algo
extends O
SVD B-Algo
model I-Algo
to O
trust O
and O
social O
recommendation O

In O
particular O
Wu O
et O
al O
proposed O
SRGNN B-Algo
that O
models O
session O
sequences O
as O
graph O
structured O
data O

proposed O
SRGNN B-Algo
that O
models O
session O
sequences O
as O
graph O
structured O
data O

proposed O
GraphRec B-Algo
for O
social O
recommendation O
to O
jointly O
model O
interactions O
and O
opinions O
in O
the O
user O
item O
graph O

A O
graph O
neural O
network O
algorithm O
called O
PinSage B-Algo
was O
proposed O

In O
recent O
years O
we O
have O
witnessed O
the O
success O
of O
graph O
representation O
learning O
in O
many O
tasks O
such O
as O
community O
detection O
link O
prediction O
graph O
classiﬁcation O

Representation O
learning O
of O
larger O
structures O
has O
generally O
been O
associated O
with O
embedding O
collections O
of O
graphs O

In O
heterogeneous O
graphs O
subgraphs O
embedding O
have O
tackled O
tasks O
such O
as O
semantic O
user O
search O
and O
question O
answering O

Our O
measure O
is O
inspired O
by O
the O
PageRank B-Algo

For O
example O
in O
matrix O
factorization O
approaches O
the O
goal O
is O
to O
perform O
dimension O
reduction O
on O
a O
matrix O
that O
encodes O
the O
pairwise O
proximity O
of O
nodes O
where O
proximity O
is O
deﬁned O
as O
adjacency O
k O
step O
transitions O
or O
Katz O
centrality O

In O
the O
authors O
propose O
a O
method O
inspired O
by O
ParagraphVector B-Algo
where O
each O
subgraph O
is O
represented O
as O
a O
collection O
of O
random O
walks O

In O
the O
authors O
present O
an O
end O
to O
end O
neural O
framework O
that O
given O
in O
input O
the O
cascade O
graph O
predicts O
the O
future O
growth O
of O
the O
cascade O
for O
a O
given O
time O
period O

is O
similarly O
an O
end O
to O
end O
neural O
framework O
for O
cascade O
prediction O

Another O
very O
important O
type O
of O
subgraph O
is O
a O
community O

In O
the O
authors O
propose O
an O
inductive O
framework O
for O
computing O
graph O
embeddings O
based O
on O
training O
an O
attention O
network O
to O
predict O
a O
graph O
proximity O
measure O
such O
as O
graph O
edit O
distance O

Graph B-Algo
embeddings I-Algo
are O
closely O
related O
to O
graph O
kernels O
functions O
that O
measure O
the O
similarity O
between O
pairs O
of O
graphs O

Graph B-Algo
kernels I-Algo
are O
used O
together O
with O
kernel B-Algomethods O
such O
as O
SVM B-Algo
to O
perform O
graph O
classiﬁcation O

In O
PageRank B-Algo
instead O
of O
teleporting O
to O
a O
random O
node O
with O
probability O
α O
the O
surfer O
teleports O
to O
a O
randomly O
chosen O
node O
from O
a O
set O
of O
predeﬁned O
seed O
nodes O

We O
compare O
with O
DeepWalk B-Algo
learns O
node O
embeddings O
by O
sampling O
random O
walks O
and O
then O
applying O
the O
SkipGram B-Algo
model I-Algo

node2vec B-Algo
is O
a O
hyperparameter O
supervised O
approach O
that O
extends O
DeepWalk B-Algo

LINE B-Algo
proposes O
two O
proximity O
measures O
for O
computing O
two O
d O
dimensional O
vectors O
for O
each O
node O

VerseAvg B-Algo
is O
a O
adaption O
of O
VERSE B-Algo
in O
which O
the O
embedding O
of O
a O
node O
is O
sub2vec B-Algo
computes O
subgraph O
embeddings O
and O
for O
the O
experimental O
evaluation O
we O
compute O
the O
embeddings O
of O
the O
ego O
networks O

We O
compare O
SubRank B-Algo
with O
the O
following O
state O
of O
the O
art O
methods O
for O
the O
task O
of O
predicting O
the O
future O
size O
of O
cascades O
DeepCas B-Algo
is O
an O
end O
to O
end O
neural O
network O
framework O
that O
given O
in O
input O
the O
cascade O
graph O
predicts O
the O
future O
growth O
of O
the O
cascade O
for O
a O
given O
period O

DeepHawkes B-Algo
is O
similarly O
an O
end O
to O
end O
deep O
learning O
framework O
for O
cascade O
prediction O

In O
addition O
we O
consider O
the O
node O
embedding O
method O
VERSE B-Algo
as O
one O
of O
the O
top O
performing O
baseline O
in O
the O
previous O
section O

This O
case O
applies O
to O
knowledge O
bases O
3D O
models O
social O
media O
and O
biological O
networks O
which O
are O
usually O
represented O
by O
graphs O

Recently O
the O
authors O
in O
propose O
dynamic O
graph O
embedding O
approach O
that O
leverage O
self O
attention O
networks O
to O
learn O
node O
representations O

In O
this O
paper O
we O
speciﬁcally O
focus O
on O
applying O
GATs B-Algo
because O
of O
its O
eﬀectiveness O
in O
addressing O
the O
shortcomings O
of O
prior O
methods O

TemporalGAT B-Algo
is O
a O
Graph O
Representation O
method O

The O
proposed O
GAT B-Algo
layer O
is O
a O
variant O
of O
GAT B-Algo
with O
dilated O
convolutions O
applied O
on O
each O
graph O
snapshot O

We O
follow O
the O
experiment O
and O
classify O
each O
node O
pair O
into O
linked O
and O
non O
linked O
nodes O
and O
use O
sampling O
approach O
to O
achieve O
positive O
and O
negative O
node O
pairs O
where O
we O
randomly O
sample O
of O
each O
snapshot O
nodes O
for O
training O
and O
use O
the O
remaining O
for O
testing O

We O
evaluate O
our O
method O
against O
the O
several O
baseline O
algorithms O
including O
static O
graph O
representation O
approaches O
such O
as O
GAT B-Algo
Node2Vec B-Algo
GraphSAGE B-Algo
GCNAE B-Algo
and O
GATAE B-Algo

Dynamic O
graph O
representation O
learning O
including O

DynamicTriad B-Algo
DynGEM B-Algo
and O
DySAT B-Algo

To O
evaluate O
the O
link O
prediction O
performance O
of O
each O
we O
train O
a O
logistic B-Algo
regression I-Algo
classiffier I-Algo
similar O
to O

Tang O
et O
al O
designed O
two O
loss O
functions O
to O
capture O
the O
local O
and O
global O
graph O
structure O

DANE B-Algo
is O
based O
on O
this O
idea O
to O
update O
the O
eigenvectors O
of O
graph O
Laplacian O
matrix O
over O
time O
series O

Recent O
works O
learn O
incremental O
node O
representations O
across O
time O
steps O
where O
the O
authors O
apply O
an O
approach O
that O
minimizes O
the O
reconstruction O
loss O
with O
a O
distance O
metric O
between O
connected O
nodes O
in O
the O
embedding O
space O

The O
ﬁrst O
category O
is O
shallow O
transfer O
learning O
such O
as O
TCA B-Algo
GFK B-Algo
SA B-Algo
KMM B-Algo
ITL B-Algo
and O
LSDT B-Algo


In O
the O
category O
of O
deep O
transfer O
learning O
discrepancy O
based O
adversarial O
based O
and O
reconstruction O
based O
algorithms O
are O
the O
three O
main O
approaches O
among O
which O
DAN B-Algo
and O
RevGrad B-Algo
are O
classical O
networks O
for O
transfer O
learning O
or O
domain O
adaptation O

In O
order O
to O
evaluate O
a O
speciﬁc O
In O
this O
paper O
we O
do O
not O
focus O
on O
the O
diﬀerence O
between O
transfer O
learning O
and O
domain O
adaptation O
we O
refer O
readers O
to O
for O
details O

The O
framework O
of O
adversarial O
domain O
adaptation O
such O
as O
RevGrad B-Algo
and O
ADDA B-Algo
utilizes O
the O
domain O
discriminator O
to O
separate O
the O
source O
and O
target O
domain O
as O
much O
as O
possible O
that O
is O
maximize O
the O
Transferability O
between O
domains O

Similarly O
discrepancy O
based O
frameworks O
such O
as O
DDC B-Algo
and O
DAN B-Algo
considering O
both O
the O
discrepancy O
loss O

analyzes O
the O
relation O
between O
adversarial O
domain O
adaptation O
via O
the O
spectral O
analysis O
of O
feature O
representations O
and O
proposed O
a O
batch O
spectral O
penalization O
algorithm O
to O
penalize O
the O
largest O
singular O
values O
to O
boost O
the O
feature O
discriminability O

ﬁrst O
addresses O
the O
gap O
between O
theories O
and O
algorithms O
and O
then O
proposes O
new O
generalization O
bounds O
and O
a O
novel O
adversarial O
domain O
adaptation O
framework O
via O
the O
introduced O
margin O
disparity O
discrepancy O

Another O
distance O
commonly O
used O
to O
measure O
the O
diﬀerence O
of O
two O
domains O
is O
MMD B-Algodistance O
a O
method O
to O
match O
higherorder O
moments O
of O
the O
domain O
distributions O

In O
this O
section O
we O
implement O
TCA B-Algo
SA B-Algo
and O
ITL B-Algo
as O
examples O
showing O
the O
diﬀerent O
mechanisms O
among O
them O

The O
result O
ﬁts O
well O
with O
the O
information O
theoretic O
factors O
considered O
in O
the O
designation O
process O
of O
ITL B-Algo
and O
we O
refer O
readers O
to O
a O
Raw O
data O

For O
the O
prediction O
experiments O
we O
only O
focus O
on O
shallow O
transfer O
learning O
algorithms O
including O
RPROJ3 B-Algo
PCA B-Algo
TCA B-Algo
MSDA B-Algo
CORAL B-Algo
GFK B-Algo
ITL B-Algo
LSDT B-Algo
GTL B-Algo
and O
KMM B-Algo

